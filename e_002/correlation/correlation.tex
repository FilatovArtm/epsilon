\documentclass[10pt]{article}

\usepackage{epsilonj}

\RequirePackage{graphicx}
\RequirePackage[colorlinks,citecolor=blue,urlcolor=blue]{hyperref}

\newcommand{\specialcell}[2][c]{\begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}

\begin{document}

\TITLE{Корреляция: простая, частная и условная}
\SHORTTITLE{Корреляция: простая, частная и условная}

\AUTHOR{Борис Демешев}{НИУ ВШЭ, Москва.}
\SHORTAUTHOR{Борис Демешев}

\DoFirstPageTechnicalStuff


\newtheorem{theorem}{Теорема}
\newtheorem{definition}{Определение}

\begin{abstract}
Корреляция "--- это способ описать силу линейной зависимости между двумя случайными величинами одним числом. Каков геометрический смысл корреляции? Что такое частная корреляция? Как связаны частная и условная корреляция? 
\end{abstract}

\begin{keyword}
корреляция, частная корреляция, условная корреляция, косинус, проекция
\end{keyword}



\section{Корреляция по-русски}

Обычно в учебниках даётся такое определение корреляции

\[
\Corr(X,Y)=\frac{\Cov(X,Y)}{\sqrt{\Var(X)\Var(Y)}}.
\]

Естественно, возникает вопрос: «С какого перепугу? Почему это мы делим ковариацию на что-то там?»

Мы дадим определение корреляции словами:

\begin{definition}
Корреляция между случайными величинами $X$ и $Y$ показывает на сколько своих стандартных отклонений в среднем растёт случайная величина $Y$ при росте случайной величины $X$ на одно своё стандартное отклонение.
\end{definition}

А теперь из этого словесного определения мы получим формулу (...). Разложим величину $Y$ на два слагаемых. Первое слагаемое вбирает в себя всю ту часть $Y$, которая линейно зависит от $X$, а второе --- всё оставшееся:

\[
\frac{Y}{\sigma_Y}=\rho \cdot \frac{X}{\sigma_X} + \varepsilon
\]

В этой формуле видно, что с ростом $X$ на одно стандартное отклонений $\sigma_X$ правая часть изменится в среднем на $\rho$, и, следовательно, величина $Y$ в среднем изменится на $\rho \cdot \sigma_Y$. 

%\[
%Y=\beta \cdot X + \varepsilon
%\]
%
%Здесь $\beta$ показывает на сколько единиц в среднем растёт $Y$ при росте $X$ на одну единицу. 

Мы хотим, чтобы ... $\Cov(X,\varepsilon)=0$. 


\[
\Cov\left(X, \frac{Y}{\sigma_Y} - \rho \cdot \frac{X}{\sigma_X} \right) = 0
\]

По свойствам ковариации получаем

\[
\Cov(X,Y)/\sigma_Y=\rho \Cov(X,X)/\sigma_X
\]

И, тадам, выражаем корреляцию, $\rho$:

\[
\rho = \frac{\Cov(X,Y)}{\sigma_X \sigma_Y}
\]

Несмотря на асимметричность исходного разложения (эпсилон прибавляется в правой части уравнения к величине $X$), результирующая формула для корреляции получается симметричной. Из этого следует, что ровно такой же результат получится, если начать с разложения:
\[
\frac{X}{\sigma_X}=\rho \cdot \frac{Y}{\sigma_Y} + \varepsilon
\]

Из определения неочевидно, что корреляция лежит в пределах от $-1$ до $1$. Здесь доказать ....



\section{Геометрический смысл корреляции}

Давайте рисовать случаные величины векторами-стрелочками! Не в том смысле, что у стрелочки случайное направление или длина, а в том смысле, что направление и длина стрелочки описывают характеристики этой случайной величины. 

Любую геометрию можно задать, задав скалярное произведение. Действительно, если мы умеем считать скалярное произведение двух любых векторов, $<\vec{a},\vec{b}>$, то длина вектора считается ровно как в 9-м классе:

\[
|\vec{a}|=\sqrt{<\vec{a},\vec{a}>}
\]

И также любой девятикласник помнит, что косинус угла между векторами считается как

\[
\cos(\vec{a},\vec{b})=\frac{<\vec{a},\vec{b}>}{|\vec{a}||\vec{b}|}
\]

Мы определим скалярное произведение двух случайных величин как их ковариацию:

\[
<X,Y>=\Cov(X,Y)
\]

При таком подходе длиной случайной величины окажется стандартное отклонение:

\[
\sqrt{\Cov(X,X)}=\sqrt{\Var(X)}=\sigma_X
\]

А корреляция окажется косинусом угла между случайными величинами:
\[
\cos(X,Y)=\frac{\Cov(X,Y)}{\sigma_X\sigma_Y}=\Corr(X,Y)
\]


Значит в нашей геометрии  длина стрелочки --- стандартное отклонение случайной величины, а косинус угла между двумя стрелочками --- это корреляция двух случайных величин. Дисперсия, следовательно, это квадрат длины случайной величины. Перпендикулярными случайными величинами будут те, косинус угла между которыми равен нулю, то есть некоррелированные.

Например, сформулируем в данной геометрии теорему Пифагора. Если есть две некоррелированные (перпендикулярные) случайные величины, то дисперсия их суммы (квадрат длины гипотенузы) равен сумме их дисперсий (сумму квадратов длин катетов).

тут картинка


\section{Корреляция и независимость}

\begin{theorem}
Случайные величины $X$ и $Y$ независимы тогда и только тогда, когда некоррелированы любые функции $f(X)$ и $g(Y)$.
\end{theorem}

Другими словами для независимости $X$ и $Y$ необходима некоррелированность пар $X$ и $Y$, $X^2$ и $\cos(Y)$, $\exp(X)$ и $1/Y$, и так далее. Из этого следует, что некоррелированность $X$ и $Y$ является необходимым, но недостаточным условием для независимости.

Многие ошибочно считают, что если величина $X$ имеет нормальное распределение $N(\mu_X, \sigma^2_X)$ и величина $Y$ имеет нормальное распределение $N(\mu_Y, \sigma^2_Y)$, и $X$ и $Y$ некоррелированы, то они независимы. Это неверно.

Контрпример. ....

Правильная теорема звучит так:

\begin{theorem}
Если некоррелированные случайные величины $X$ и $Y$ имеют совместное нормальное распределение, то $X$ и $Y$ независимы.
\end{theorem}

Попутно упомянем ещё одно неожиданное свойство предъявленного контрпримера. Если случайные величины нормальны по отдельности, то вполне возможно, что их сумма ненормальна. Для пары величин, имеющих совместное нормальное распределение, это невозможно.


\section{Частная корреляция}

\begin{definition}
Частная корреляция между величинами $X$ и $Y$ при фиксированной величине $Z$ показывает на сколько своих стандартных отклонений $\sigma_Y$ в среднем вырастет $Y$ при росте величины $X$ на одно своё стандартное отклонение $\sigma_X$ и постоянном значении величины $Z$.
\end{definition}

Для нахождения частной корреляции используется разложение
\[
\frac{Y}{\sigma_Y}=\rho_{XY|Z} \cdot \frac{X}{\sigma_X} + \rho_{YZ|X} \frac{Z}{\sigma_Z} + \varepsilon
\]


Обозначение???

Геометрическая интерпретация

\section{Условная корреляция}

\begin{definition}
Условная корреляция между величинами $X$ и $Y$ при известном значении величины $Z$ показывает на сколько своих стандартных отклонений $\sigma_Y$ в среднем вырастет $Y$ при росте величины $X$ на одно своё стандартное отклонение $\sigma_X$ при заданном значении величины $Z$.
\end{definition}


Следует подчеркнуть одно существенное отличие условной корреляции от обычной и частной. Обычная и частная корреляция являеются константами. Условная корреляция $\Corr(X,Y|Z)$ является функцией от $Z$. Величина $Z$ является случайной, поэтому и условная корреляция $\Corr(X,Y|Z)$ является случайной величиной. 

Здесь регрессионное определение???? 

Чуть более формальное определение:

\begin{definition}
\[
\Corr(X,Y|Z) = \frac{\Cov(X,Y|Z)}{\sqrt{\Var(X|Z)\Var(Y|Z)}},
\]
\end{definition}

где $\Cov(X,Y|Z)=\E(XY|Z)-\E(X|Z)\E(Y|Z)$ и $\Var(X|Z)=\E(X^2|Z)-(\E(X|Z))^2$


Пример подсчета частной и условной корреляций.

\begin{theorem}
Если величины $X$, $Y$ и $Z$ имеют совместное нормальное распределение, то частная и условная корреляции совпадают.
\end{theorem}

\end{document}


